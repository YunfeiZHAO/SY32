{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from scipy.stats import norm\n",
    "from sklearn.model_selection import KFold\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a210af5d0>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# sns.scatterplot(X_train.squeeze(), y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class CatClassifier():\n",
    "    \"\"\" Classifieur de chats \n",
    "    \n",
    "    On distingue deux types de chat : type A (-1) et type B (+1).\n",
    "    On classifie les chats en fonction de leur poids x à l'aide du classifier\n",
    "    f_h défini telle que : f_h(x) = -1 si x <= h et +1 sinon.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    \n",
    "    Attributes\n",
    "    ----------\n",
    "    h_hat : float\n",
    "            Valeur optimale de h.\n",
    "    \n",
    "    \"\"\"\n",
    "    h_hat = -np.Inf\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def predict(self, X, h=None):\n",
    "        \"\"\"\n",
    "        Prédit le type de chat pour les poids X et le paramètre h\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like of shape (n_sample, n_features)\n",
    "            Poids des chats\n",
    "        \n",
    "        h : float (default=h_hat)\n",
    "            Paramètre de décision \n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        y : array-like of shape (n_samples,)\n",
    "            Type des chats\n",
    "        \"\"\"\n",
    "        if h is None:\n",
    "            h = self.h_hat\n",
    "        # TODO\n",
    "        ## append\n",
    "        '''\n",
    "        y = np.array([])\n",
    "        for x in np.nditer(X, order = 'C'): \n",
    "            if x <= h:\n",
    "                y = np.append(y, -1)\n",
    "            else:\n",
    "                y = np.append(y, 1)  \n",
    "        return y  \n",
    "        '''\n",
    "        ## pre allocate\n",
    "        '''\n",
    "        y = np.zeros(len(X))\n",
    "        for i, x in enumerate(X):\n",
    "        if x <= h:\n",
    "            y[i] = -1\n",
    "        else:\n",
    "            y[i] = 1\n",
    "        return y       \n",
    "        '''\n",
    "        ## return \n",
    "        '''\n",
    "        return [-1 if x<=h h else 1 for x in X]\n",
    "        '''\n",
    "\n",
    "        ## sans boucle\n",
    "        # t = time.time()\n",
    "        return ((X>h)*2-1).flatten()\n",
    "        # time = time.time() - t\n",
    "    \n",
    "    def err_emp(self, X, y, h=None):\n",
    "        \"\"\"\n",
    "        Calcule l'erreur empirique de f_h sur l'ensemble (X,y).\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like of shape (n_sample, n_features)\n",
    "            Poids des chats\n",
    "            \n",
    "        y : array-like of shape (n_samples,)\n",
    "            Type des chats\n",
    "            \n",
    "        h : float (default=h_hat)\n",
    "            Paramètre de décision \n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        erreur : float\n",
    "                 Erreur empirique\n",
    "\n",
    "        \"\"\"\n",
    "        if h is None:\n",
    "            h = self.h_hat\n",
    "        \n",
    "        # TODO\n",
    "        y_pred = self.predict(X, h)\n",
    "        TP = np.sum(y_pred!=y)\n",
    "        N = len(y)\n",
    "        return TP/N\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Calcule la valeur optimale de h sur l'ensemble (X,y).\n",
    "        L'attribut h_hat est mis à jour.'\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like of shape (n_sample, n_features)\n",
    "            Poids des chats\n",
    "        \n",
    "        y : array-like of shape (n_samples,)\n",
    "            Type des chats\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        self : object\n",
    "        \"\"\"\n",
    "        \n",
    "        # TODO\n",
    "        # method1: space = np.arange(np.min(silf.X_train), np.max(self.X_train), 0.01)\n",
    "        # method2: the result change only when we pass a point\n",
    "        \n",
    "        # for h in space:\n",
    "        err_min = 1\n",
    "        for h in np.nditer(X):\n",
    "            err = self.err_emp(X, y, h)\n",
    "            if err < err_min:\n",
    "                err_min = err\n",
    "                self.h_hat = h\n",
    "        return self\n",
    "    \n",
    "# nlog(n) (faire un trie, resolutino opitmal)\n",
    "\n",
    "# K-Fold Cross Validation\n",
    "# sublist\n",
    "# masque: M=[true,true..]\n",
    "# evaluer la performance de la methode\n",
    "# k-fold: k by order\n",
    "# shuffle split: random\n",
    "# stratifiedKFord: same proportion of each class\n",
    "# stratified shuffle split: random min each class\n",
    "    def cv(self, X, y, K):\n",
    "        l = len(y)\n",
    "        unit = l//K\n",
    "        Err = []\n",
    "        for k in np.arange(K):\n",
    "            s = k*unit\n",
    "            mask = np.zeros(y.size, dtype=bool)\n",
    "            if(k < K-1):\n",
    "                mask[s: s+unit] = True\n",
    "            else:\n",
    "                mask[s:] = True\n",
    "            x_valide = X[mask]\n",
    "            y_valide = y[mask]\n",
    "            x_train = X[~mask]\n",
    "            y_train = y[~mask]\n",
    "            self.fit(x_train, y_train)\n",
    "            te = self.err_emp(x_valide, y_valide)\n",
    "            Err.append(te)\n",
    "        return np.mean(Err)\n",
    "    \n",
    "    def cv_sk(self, X, y, K):\n",
    "        kf = KFold(n_splits=K)\n",
    "        err = []\n",
    "        for train, val in kf.split(X):\n",
    "            self.fit(X[train], y[train])\n",
    "            err.append(self.err_emp(X[val], y[val]))\n",
    "        err_cv = np.mean(err)\n",
    "        return err_cv\n",
    "\n",
    "    def afficher_cross_vaidation1(self, X, y):\n",
    "        err = []\n",
    "        for k in range(2, 11):\n",
    "            err.append(self.cv(X, y, k))\n",
    "        plt.plot(range(1, 10), err)\n",
    "        print(np.mean(err))\n",
    "        plt.show()\n",
    "        \n",
    "    def afficher_cross_vaidation2(self, X, y):\n",
    "        err = []\n",
    "        for k in range(2, 11):\n",
    "            err.append(self.cv_sk(X, y, k))\n",
    "        plt.plot(range(1, 10), err)\n",
    "        print(np.mean(err))\n",
    "        plt.show()\n",
    "    \n",
    "\n",
    "    def err_theo(self, h, mu1=4, sigma1=1, mu2=6, sigma2=1, p1 =1/3):\n",
    "        p2 = 1-p1\n",
    "        return (1-norm.cdf(h, mu1, sigma1))*p1 + norm.cdf(h, mu2, sigma2)*p2\n",
    "# if __name__ == \"__main__\":\n",
    "#     X_train = np.loadtxt('/Users/yunfei/Desktop/GI05/SY32/td01/data/SY32_P20_TD01_data_X.csv', ndmin=2)\n",
    "#     y_train = np.loadtxt('/Users/yunfei/Desktop/GI05/SY32/td01/data/SY32_P20_TD01_data_y.csv')\n",
    "#     clf = CatClassifier()\n",
    "#     print(clf.predict(X_train, 5))\n",
    "#     print(clf.err_emp(X_train, y_train, 5)) #0.15333333333333332\n",
    "#     print(clf.fit(X_train, y_train).h_hat) #4.62\n",
    "#     clf.fit(X_train, y_train)\n",
    "#     clf.h_hat\n",
    "#     clf.err_emp(X_train, y_train) #0.12666666666666668\n",
    "#     TE = clf.err_emp(X_train, y_train)\n",
    "#     Taux d'erreur réel (pour h = 4,62) : 14,51\n",
    "#     print(clf.err_theo(4.62))\n",
    "#     print(clf.cv(X_train, y_train, 4))\n",
    "#     clf.afficher_cross_vaidation1(X_train, y_train)\n",
    "#     clf.afficher_cross_vaidation2(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## visualisation cross validation\n",
    "https://scikit-learn.org/stable/auto_examples/model_selection/plot_cv_indices.html#sphx-glr-auto-examples-model-selection-plot-cv-indices-py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifieur multi-dimensionnel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.CatClassifierMultiDim at 0x1a2362a490>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array(46.679)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class CatClassifierMultiDim():\n",
    "    \"\"\" Classifieur de chats \n",
    "    \n",
    "    On distingue deux types de chat : type A (-1) et type B (+1).\n",
    "    On classifie les chats en fonction de leur poids et leur taille x à l'aide du classifier\n",
    "    f_h défini telle que : f_h(x[d]) = z si x <= h et -z sinon.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    \n",
    "    Attributes\n",
    "    ----------\n",
    "    h_hat : float\n",
    "            Valeur optimale de h.\n",
    "    d : integer\n",
    "        colonne de x choisi\n",
    "    z : -1 ou +1\n",
    "    \n",
    "    \"\"\"\n",
    "    h_hat = -np.Inf\n",
    "    d = 0\n",
    "    z = -1\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def predict(self, X, h=None, d=None, z=None):\n",
    "        D = X_train.shape[1]\n",
    "        if h is None:\n",
    "            h = self.h_hat\n",
    "        if d is None or d > D:\n",
    "            d = self.d\n",
    "        if z != 1 and z != -1:\n",
    "            z = self.z\n",
    "        return ((X[:,d]<=h)*2-1)*z\n",
    "    \n",
    "    def err_emp(self, X, y, h=None, d=None, z=None):\n",
    "        if h is None:\n",
    "            h = self.h_hat\n",
    "        if d is None or d > X_train.shape[1]:\n",
    "            d = self.d\n",
    "        if z != 1 and z != -1:\n",
    "            z = self.z\n",
    "        y_pred = self.predict(X, h, d ,z)\n",
    "        TP = np.sum(y_pred!=y)\n",
    "        N = len(y)\n",
    "        return TP/N\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        err_min = 1\n",
    "        for d in np.arange(X_train.shape[1]):\n",
    "            for z in [-1, 1]:\n",
    "                for h in np.nditer(X[:,d]):\n",
    "                    err = self.err_emp(X, y, h, d, z)\n",
    "                    if err < err_min:\n",
    "                        err_min = err\n",
    "                        self.h_hat = h\n",
    "                        self.d = d\n",
    "                        self.z = z\n",
    "        return self\n",
    "\n",
    "    def cv(self, X, y, K):\n",
    "        l = len(y)\n",
    "        unit = l//K\n",
    "        Err = []\n",
    "        for k in np.arange(K):\n",
    "            s = k*unit\n",
    "            mask = np.zeros(y.size, dtype=bool)\n",
    "            if(k < K-1):\n",
    "                mask[s: s+unit] = True\n",
    "            else:\n",
    "                mask[s:] = True\n",
    "            x_valide = X[mask]\n",
    "            y_valide = y[mask]\n",
    "            x_train = X[~mask]\n",
    "            y_train = y[~mask]\n",
    "            self.fit(x_train, y_train)\n",
    "            te = self.err_emp(x_valide, y_valide)\n",
    "            Err.append(te)\n",
    "        return np.mean(Err)\n",
    "    \n",
    "    def cv_sk(self, X, y, K):\n",
    "        kf = KFold(n_splits=K)\n",
    "        err = []\n",
    "        for train, val in kf.split(X):\n",
    "            self.fit(X[train], y[train])\n",
    "            err.append(self.err_emp(X[val], y[val]))\n",
    "        err_cv = np.mean(err)\n",
    "        return err_cv\n",
    "\n",
    "    def afficher_cross_vaidation1(self, X, y):\n",
    "        err = []\n",
    "        for k in range(2, 11):\n",
    "            err.append(self.cv(X, y, k))\n",
    "        plt.plot(range(1, 10), err)\n",
    "        print(np.mean(err))\n",
    "        plt.show()\n",
    "        \n",
    "    def afficher_cross_vaidation2(self, X, y):\n",
    "        err = []\n",
    "        for k in range(2, 11):\n",
    "            err.append(self.cv_sk(X, y, k))\n",
    "        plt.plot(range(1, 10), err)\n",
    "        print(np.mean(err))\n",
    "        plt.show()                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() takes 3 positional arguments but 4 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-49-f9bbf08ec302>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloadtxt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/Users/yunfei/Desktop/GI05/SY32/td02/data/SY32_P20_TD02_data_y_train.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0mX_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloadtxt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/Users/yunfei/Desktop/GI05/SY32/td02/data/SY32_P20_TD02_data_X_test.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mndmin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m     \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCatClassifierBoost\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m     \u001b[0my_hat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdaboost\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;31m#     clf.fit(X_train, y_train)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() takes 3 positional arguments but 4 were given"
     ]
    }
   ],
   "source": [
    "class CatClassifierBoost(CatClassifierMultiDim):\n",
    "    def __init__(X, y, K):\n",
    "        self.p = np.zeros(y.size)\n",
    "        self.p = 1/y.size\n",
    "        self.K = K\n",
    "        self.alpha = np.zeros(K)\n",
    "        self.h_hat = np.zeros(K)\n",
    "        self.d = np.zeros(K)\n",
    "        self.z = n--p.zeros(K)\n",
    "        for i in range(self.K):\n",
    "            clf.fit_k(X, y, i)\n",
    "\n",
    "    def err_emp(self, X, p, y, h, d, z):\n",
    "        if h is None:\n",
    "            h = self.h_hat\n",
    "        if d is None or d > X_train.shape[1]:\n",
    "            d = self.d\n",
    "        if z != 1 and z != -1:\n",
    "            z = self.z\n",
    "        y_pred = self.predict(X, p, h, d ,z)\n",
    "        return np.sum((y_pred!=y)*p)\n",
    "       \n",
    "    def fit_k(self, X, y, k, p):\n",
    "        if p is None:\n",
    "            p = self.p\n",
    "        err_min = 1\n",
    "        for d in np.arange(X_train.shape[1]):\n",
    "            for z in [-1, 1]:\n",
    "                for h in np.nditer(X[:,d]):\n",
    "                    err = self.err_emp(X, p, y, h, d, z)\n",
    "                    if err < err_min:\n",
    "                        err_min = err\n",
    "                        self.h_hat[k] = h\n",
    "                        self.d[k] = d\n",
    "                        self.z[k] = z\n",
    "                        self.alpha[k] = (1/2)*np.log((1-err_min)/err_min)\n",
    "                        self.p = self.p * np.log(-alpha[k]*y*predict(X))/(2*np.sqrt(err_min*(1-err_min)))\n",
    "    def Adaboost(self, X):\n",
    "        s = 0\n",
    "        for h, d, z, i in zip(self.h_hat, self.d, self.z, self.K):\n",
    "            s = s + self.alpha[i]*self.predict(X, h, d, z)\n",
    "        if s > 0:\n",
    "            return 1\n",
    "        else:\n",
    "            return -1\n",
    "        \n",
    "if __name__ == \"__main__\":\n",
    "    X_train = np.loadtxt('/Users/yunfei/Desktop/GI05/SY32/td02/data/SY32_P20_TD02_data_X_train.csv', ndmin=2)\n",
    "    y_train = np.loadtxt('/Users/yunfei/Desktop/GI05/SY32/td02/data/SY32_P20_TD02_data_y_train.csv')\n",
    "    X_test = np.loadtxt('/Users/yunfei/Desktop/GI05/SY32/td02/data/SY32_P20_TD02_data_X_test.csv', ndmin=2)\n",
    "    clf = CatClassifierBoost(X_train, y_train,10)\n",
    "    y_hat = clf.Adaboost(X_test)\n",
    "#     clf.fit(X_train, y_train)\n",
    "#     clf.h_hat\n",
    "#     clf.d\n",
    "#     clf.z    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sy32",
   "language": "python",
   "name": "sy32"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
